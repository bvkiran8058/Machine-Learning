{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income (in $1000s)</th>\n",
       "      <th>Online Hours Per Week</th>\n",
       "      <th>Purchase Frequency (Last Month)</th>\n",
       "      <th>Is Loyal Customer</th>\n",
       "      <th>Preferred Shopping Platform</th>\n",
       "      <th>Ad Clicks (Last Month)</th>\n",
       "      <th>Discounts Used (Last Month)</th>\n",
       "      <th>Competitor Pricing Index</th>\n",
       "      <th>Economic Conditions</th>\n",
       "      <th>Distance to Nearest Store (km)</th>\n",
       "      <th>Shopping Frequency</th>\n",
       "      <th>Purchase Decision (1=Yes, 0=No)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>Female</td>\n",
       "      <td>91.97</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Website</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.83</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>43.09</td>\n",
       "      <td>1.685360</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>Male</td>\n",
       "      <td>22.29</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Website</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1.13</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>16.78</td>\n",
       "      <td>15.337143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>Female</td>\n",
       "      <td>50.59</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Website</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.06</td>\n",
       "      <td>Favorable</td>\n",
       "      <td>9.80</td>\n",
       "      <td>17.530050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>Male</td>\n",
       "      <td>58.63</td>\n",
       "      <td>49</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>In-store</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.94</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2.78</td>\n",
       "      <td>28.540342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>Female</td>\n",
       "      <td>44.87</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mobile App</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.87</td>\n",
       "      <td>Unfavorable</td>\n",
       "      <td>49.22</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Income (in $1000s)  Online Hours Per Week  \\\n",
       "0   56  Female               91.97                     49   \n",
       "1   69    Male               22.29                      1   \n",
       "2   46  Female               50.59                      3   \n",
       "3   32    Male               58.63                     49   \n",
       "4   60  Female               44.87                     27   \n",
       "\n",
       "   Purchase Frequency (Last Month)  Is Loyal Customer  \\\n",
       "0                                7                  0   \n",
       "1                                2                  1   \n",
       "2                                7                  0   \n",
       "3                               14                  1   \n",
       "4                                0                  0   \n",
       "\n",
       "  Preferred Shopping Platform  Ad Clicks (Last Month)  \\\n",
       "0                     Website                       1   \n",
       "1                     Website                       9   \n",
       "2                     Website                       0   \n",
       "3                    In-store                       0   \n",
       "4                  Mobile App                       7   \n",
       "\n",
       "   Discounts Used (Last Month)  Competitor Pricing Index Economic Conditions  \\\n",
       "0                            9                      0.83             Neutral   \n",
       "1                            3                      1.13             Neutral   \n",
       "2                            2                      1.06           Favorable   \n",
       "3                            8                      0.94             Neutral   \n",
       "4                            9                      0.87         Unfavorable   \n",
       "\n",
       "   Distance to Nearest Store (km)  Shopping Frequency  \\\n",
       "0                           43.09            1.685360   \n",
       "1                           16.78           15.337143   \n",
       "2                            9.80           17.530050   \n",
       "3                            2.78           28.540342   \n",
       "4                           49.22            1.000000   \n",
       "\n",
       "   Purchase Decision (1=Yes, 0=No)  \n",
       "0                                1  \n",
       "1                                1  \n",
       "2                                1  \n",
       "3                                1  \n",
       "4                                1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Datasets/customer_behavior_dataset.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 14 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Age                              5000 non-null   int64  \n",
      " 1   Gender                           5000 non-null   object \n",
      " 2   Income (in $1000s)               4800 non-null   float64\n",
      " 3   Online Hours Per Week            5000 non-null   int64  \n",
      " 4   Purchase Frequency (Last Month)  5000 non-null   int64  \n",
      " 5   Is Loyal Customer                5000 non-null   int64  \n",
      " 6   Preferred Shopping Platform      5000 non-null   object \n",
      " 7   Ad Clicks (Last Month)           5000 non-null   int64  \n",
      " 8   Discounts Used (Last Month)      5000 non-null   int64  \n",
      " 9   Competitor Pricing Index         5000 non-null   float64\n",
      " 10  Economic Conditions              4850 non-null   object \n",
      " 11  Distance to Nearest Store (km)   5000 non-null   float64\n",
      " 12  Shopping Frequency               5000 non-null   float64\n",
      " 13  Purchase Decision (1=Yes, 0=No)  5000 non-null   int64  \n",
      "dtypes: float64(4), int64(7), object(3)\n",
      "memory usage: 547.0+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4660, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since missing values are low dropping is best opion\n",
    "dataset = dataset.dropna()\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender: ['Female' 'Male']\n",
      "Preferred Shopping Platform: ['Website' 'In-store' 'Mobile App']\n",
      "Economic Conditions: ['Neutral' 'Favorable' 'Unfavorable']\n"
     ]
    }
   ],
   "source": [
    "categorical_features = ['Gender','Preferred Shopping Platform', 'Economic Conditions']\n",
    "for f in categorical_features:\n",
    "    print(f'{f}: {dataset[f].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "one_hot_encoded = ohe.fit_transform(dataset[['Gender']])\n",
    "ohe_hot_encoded_df = pd.DataFrame(one_hot_encoded, columns=ohe.get_feature_names_out(['Gender']))\n",
    "le = LabelEncoder()\n",
    "encoded_dataset1 = dataset.copy()\n",
    "for f in categorical_features:\n",
    "    if f != 'Gender':  \n",
    "        encoded_dataset1[f] = le.fit_transform(encoded_dataset1[f])\n",
    "\n",
    "encoded_dataset = pd.concat(\n",
    "    [encoded_dataset1.drop(columns=['Gender'], axis=1).reset_index(drop=True), ohe_hot_encoded_df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[56.        , 91.97      , 49.        , ...,  1.68536028,\n",
       "          1.        ,  0.        ],\n",
       "        [69.        , 22.29      ,  1.        , ..., 15.33714311,\n",
       "          0.        ,  1.        ],\n",
       "        [46.        , 50.59      ,  3.        , ..., 17.53005006,\n",
       "          1.        ,  0.        ],\n",
       "        ...,\n",
       "        [26.        , 53.61      ,  9.        , ...,  1.        ,\n",
       "          0.        ,  1.        ],\n",
       "        [53.        , 42.04      ,  5.        , ..., 16.73424535,\n",
       "          1.        ,  0.        ],\n",
       "        [36.        , 55.16      ,  6.        , ..., 11.57171689,\n",
       "          1.        ,  0.        ]], shape=(4660, 14)),\n",
       " array([1, 1, 1, ..., 1, 1, 1], shape=(4660,)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = encoded_dataset.drop(columns=['Purchase Decision (1=Yes, 0=No)'], axis=1).values, encoded_dataset['Purchase Decision (1=Yes, 0=No)'].values\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.37682941,  1.2497109 , -0.99712663, ...,  1.77213258,\n",
       "         -0.99145283,  0.99145283],\n",
       "        [ 0.75095395,  0.50765692, -0.92815366, ...,  1.80100262,\n",
       "          1.00862085, -1.00862085],\n",
       "        [ 1.34801573, -0.42815006,  0.17541377, ...,  0.55682696,\n",
       "         -0.99145283,  0.99145283],\n",
       "        ...,\n",
       "        [-0.31048921,  0.4192696 , -0.03150512, ...,  1.31166512,\n",
       "         -0.99145283,  0.99145283],\n",
       "        [ 0.35291277,  0.18756499,  1.55487306, ...,  1.64263582,\n",
       "          1.00862085, -1.00862085],\n",
       "        [-1.04023138,  0.42725941,  0.45130563, ...,  0.78783563,\n",
       "         -0.99145283,  0.99145283]], shape=(3262, 14)),\n",
       " array([[ 1.14899514, -0.77570697,  0.45130563, ...,  1.54416   ,\n",
       "         -0.99145283,  0.99145283],\n",
       "        [ 0.35291277,  0.90964444,  0.79617045, ..., -1.56080825,\n",
       "          1.00862085, -1.00862085],\n",
       "        [ 0.81729415,  0.11915221, -1.06609959, ...,  0.14621527,\n",
       "         -0.99145283,  0.99145283],\n",
       "        ...,\n",
       "        [ 1.28167553,  0.68592964,  1.34795416, ..., -1.31539714,\n",
       "         -0.99145283,  0.99145283],\n",
       "        [-0.31048921, -0.46160741, -0.10047809, ...,  0.41711369,\n",
       "         -0.99145283,  0.99145283],\n",
       "        [-0.37682941, -0.82514395,  1.41692713, ..., -1.54650861,\n",
       "          1.00862085, -1.00862085]], shape=(1398, 14)),\n",
       " array([1, 1, 1, ..., 1, 1, 1], shape=(3262,)),\n",
       " array([1, 1, 1, ..., 1, 1, 1], shape=(1398,)))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled, X_test_scaled = scaler.fit_transform(X_train), scaler.transform(X_test)\n",
    "X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9914163090128756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      1.00      0.14         1\n",
      "           1       1.00      0.99      1.00      1397\n",
      "\n",
      "    accuracy                           0.99      1398\n",
      "   macro avg       0.54      1.00      0.57      1398\n",
      "weighted avg       1.00      0.99      1.00      1398\n",
      "\n",
      "[[   1    0]\n",
      " [  12 1385]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "logiregressor = LogisticRegression()\n",
    "logiregressor.fit(X_train_scaled, y_train)\n",
    "y_pred=logiregressor.predict(X_test_scaled)\n",
    "print(f'accuracy: {accuracy_score(y_pred,y_test)}')\n",
    "print(classification_report(y_pred,y_test))\n",
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets try without dropping NAN values instead adding mode or mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income (in $1000s)</th>\n",
       "      <th>Online Hours Per Week</th>\n",
       "      <th>Purchase Frequency (Last Month)</th>\n",
       "      <th>Is Loyal Customer</th>\n",
       "      <th>Preferred Shopping Platform</th>\n",
       "      <th>Ad Clicks (Last Month)</th>\n",
       "      <th>Discounts Used (Last Month)</th>\n",
       "      <th>Competitor Pricing Index</th>\n",
       "      <th>Economic Conditions</th>\n",
       "      <th>Distance to Nearest Store (km)</th>\n",
       "      <th>Shopping Frequency</th>\n",
       "      <th>Purchase Decision (1=Yes, 0=No)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>Female</td>\n",
       "      <td>91.97</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Website</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.83</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>43.09</td>\n",
       "      <td>1.685360</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>Male</td>\n",
       "      <td>22.29</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Website</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1.13</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>16.78</td>\n",
       "      <td>15.337143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>Female</td>\n",
       "      <td>50.59</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Website</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.06</td>\n",
       "      <td>Favorable</td>\n",
       "      <td>9.80</td>\n",
       "      <td>17.530050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>Male</td>\n",
       "      <td>58.63</td>\n",
       "      <td>49</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>In-store</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.94</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2.78</td>\n",
       "      <td>28.540342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>Female</td>\n",
       "      <td>44.87</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mobile App</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.87</td>\n",
       "      <td>Unfavorable</td>\n",
       "      <td>49.22</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Income (in $1000s)  Online Hours Per Week  \\\n",
       "0   56  Female               91.97                     49   \n",
       "1   69    Male               22.29                      1   \n",
       "2   46  Female               50.59                      3   \n",
       "3   32    Male               58.63                     49   \n",
       "4   60  Female               44.87                     27   \n",
       "\n",
       "   Purchase Frequency (Last Month)  Is Loyal Customer  \\\n",
       "0                                7                  0   \n",
       "1                                2                  1   \n",
       "2                                7                  0   \n",
       "3                               14                  1   \n",
       "4                                0                  0   \n",
       "\n",
       "  Preferred Shopping Platform  Ad Clicks (Last Month)  \\\n",
       "0                     Website                       1   \n",
       "1                     Website                       9   \n",
       "2                     Website                       0   \n",
       "3                    In-store                       0   \n",
       "4                  Mobile App                       7   \n",
       "\n",
       "   Discounts Used (Last Month)  Competitor Pricing Index Economic Conditions  \\\n",
       "0                            9                      0.83             Neutral   \n",
       "1                            3                      1.13             Neutral   \n",
       "2                            2                      1.06           Favorable   \n",
       "3                            8                      0.94             Neutral   \n",
       "4                            9                      0.87         Unfavorable   \n",
       "\n",
       "   Distance to Nearest Store (km)  Shopping Frequency  \\\n",
       "0                           43.09            1.685360   \n",
       "1                           16.78           15.337143   \n",
       "2                            9.80           17.530050   \n",
       "3                            2.78           28.540342   \n",
       "4                           49.22            1.000000   \n",
       "\n",
       "   Purchase Decision (1=Yes, 0=No)  \n",
       "0                                1  \n",
       "1                                1  \n",
       "2                                1  \n",
       "3                                1  \n",
       "4                                1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Datasets/customer_behavior_dataset.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 14 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Age                              5000 non-null   int64  \n",
      " 1   Gender                           5000 non-null   object \n",
      " 2   Income (in $1000s)               4800 non-null   float64\n",
      " 3   Online Hours Per Week            5000 non-null   int64  \n",
      " 4   Purchase Frequency (Last Month)  5000 non-null   int64  \n",
      " 5   Is Loyal Customer                5000 non-null   int64  \n",
      " 6   Preferred Shopping Platform      5000 non-null   object \n",
      " 7   Ad Clicks (Last Month)           5000 non-null   int64  \n",
      " 8   Discounts Used (Last Month)      5000 non-null   int64  \n",
      " 9   Competitor Pricing Index         5000 non-null   float64\n",
      " 10  Economic Conditions              4850 non-null   object \n",
      " 11  Distance to Nearest Store (km)   5000 non-null   float64\n",
      " 12  Shopping Frequency               5000 non-null   float64\n",
      " 13  Purchase Decision (1=Yes, 0=No)  5000 non-null   int64  \n",
      "dtypes: float64(4), int64(7), object(3)\n",
      "memory usage: 547.0+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 14 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Age                              5000 non-null   int64  \n",
      " 1   Gender                           5000 non-null   object \n",
      " 2   Income (in $1000s)               5000 non-null   float64\n",
      " 3   Online Hours Per Week            5000 non-null   int64  \n",
      " 4   Purchase Frequency (Last Month)  5000 non-null   int64  \n",
      " 5   Is Loyal Customer                5000 non-null   int64  \n",
      " 6   Preferred Shopping Platform      5000 non-null   object \n",
      " 7   Ad Clicks (Last Month)           5000 non-null   int64  \n",
      " 8   Discounts Used (Last Month)      5000 non-null   int64  \n",
      " 9   Competitor Pricing Index         5000 non-null   float64\n",
      " 10  Economic Conditions              5000 non-null   object \n",
      " 11  Distance to Nearest Store (km)   5000 non-null   float64\n",
      " 12  Shopping Frequency               5000 non-null   float64\n",
      " 13  Purchase Decision (1=Yes, 0=No)  5000 non-null   int64  \n",
      "dtypes: float64(4), int64(7), object(3)\n",
      "memory usage: 547.0+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset['Income (in $1000s)'] = dataset['Income (in $1000s)'].fillna(dataset['Income (in $1000s)'].mean())\n",
    "dataset['Economic Conditions'] = dataset['Economic Conditions'].fillna(dataset['Economic Conditions'].mode()[0])\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "one_hot_encoded = ohe.fit_transform(dataset[['Gender']])\n",
    "ohe_hot_encoded_df = pd.DataFrame(one_hot_encoded, columns=ohe.get_feature_names_out(['Gender']))\n",
    "le = LabelEncoder()\n",
    "encoded_dataset1 = dataset.copy()\n",
    "for f in categorical_features:\n",
    "    if f != 'Gender':  \n",
    "        encoded_dataset1[f] = le.fit_transform(encoded_dataset1[f])\n",
    "\n",
    "encoded_dataset = pd.concat(\n",
    "    [encoded_dataset1.drop(columns=['Gender'], axis=1).reset_index(drop=True), ohe_hot_encoded_df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Age                              5000 non-null   int64  \n",
      " 1   Income (in $1000s)               5000 non-null   float64\n",
      " 2   Online Hours Per Week            5000 non-null   int64  \n",
      " 3   Purchase Frequency (Last Month)  5000 non-null   int64  \n",
      " 4   Is Loyal Customer                5000 non-null   int64  \n",
      " 5   Preferred Shopping Platform      5000 non-null   int64  \n",
      " 6   Ad Clicks (Last Month)           5000 non-null   int64  \n",
      " 7   Discounts Used (Last Month)      5000 non-null   int64  \n",
      " 8   Competitor Pricing Index         5000 non-null   float64\n",
      " 9   Economic Conditions              5000 non-null   int64  \n",
      " 10  Distance to Nearest Store (km)   5000 non-null   float64\n",
      " 11  Shopping Frequency               5000 non-null   float64\n",
      " 12  Purchase Decision (1=Yes, 0=No)  5000 non-null   int64  \n",
      " 13  Gender_Female                    5000 non-null   float64\n",
      " 14  Gender_Male                      5000 non-null   float64\n",
      "dtypes: float64(6), int64(9)\n",
      "memory usage: 586.1 KB\n"
     ]
    }
   ],
   "source": [
    "encoded_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[56.        , 91.97      , 49.        , ...,  1.68536028,\n",
       "          1.        ,  0.        ],\n",
       "        [69.        , 22.29      ,  1.        , ..., 15.33714311,\n",
       "          0.        ,  1.        ],\n",
       "        [46.        , 50.59      ,  3.        , ..., 17.53005006,\n",
       "          1.        ,  0.        ],\n",
       "        ...,\n",
       "        [26.        , 53.61      ,  9.        , ...,  1.        ,\n",
       "          0.        ,  1.        ],\n",
       "        [53.        , 42.04      ,  5.        , ..., 16.73424535,\n",
       "          1.        ,  0.        ],\n",
       "        [36.        , 55.16      ,  6.        , ..., 11.57171689,\n",
       "          1.        ,  0.        ]], shape=(5000, 14)),\n",
       " array([1, 1, 1, ..., 1, 1, 1], shape=(5000,)))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = encoded_dataset.drop(columns=['Purchase Decision (1=Yes, 0=No)'], axis=1).values, encoded_dataset['Purchase Decision (1=Yes, 0=No)'].values\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.91132783, -0.69066401, -0.97738846, ...,  0.62440367,\n",
       "         -0.96628239,  0.96628239],\n",
       "        [-0.84481864,  1.23577697, -0.42499096, ..., -0.96644206,\n",
       "          1.03489416, -1.03489416],\n",
       "        [-1.31038292, -0.84827728,  1.57744997, ..., -0.31426032,\n",
       "          1.03489416, -1.03489416],\n",
       "        ...,\n",
       "        [ 0.48536501, -1.59312712, -0.90833877, ...,  0.34414191,\n",
       "          1.03489416, -1.03489416],\n",
       "        [-1.64292884,  2.03757095,  0.61075435, ..., -1.38317761,\n",
       "         -0.96628239,  0.96628239],\n",
       "        [ 0.48536501, -1.79599066, -0.07974252, ..., -1.10516458,\n",
       "          1.03489416, -1.03489416]], shape=(3500, 14)),\n",
       " array([[ 1.01743848,  0.53160153, -0.14879221, ...,  1.44056795,\n",
       "          1.03489416, -1.03489416],\n",
       "        [-1.24387374, -1.56109603,  1.50840028, ...,  0.55237516,\n",
       "         -0.96628239,  0.96628239],\n",
       "        [-0.37925436, -0.03173883, -1.66788533, ...,  0.988138  ,\n",
       "         -0.96628239,  0.96628239],\n",
       "        ...,\n",
       "        [ 0.41885583,  1.4503344 , -0.63214002, ..., -0.98827631,\n",
       "          1.03489416, -1.03489416],\n",
       "        [-0.17972681,  0.34348246, -1.32263689, ...,  0.71589411,\n",
       "         -0.96628239,  0.96628239],\n",
       "        [-0.31274518, -1.54228412, -1.04643814, ...,  1.47912978,\n",
       "         -0.96628239,  0.96628239]], shape=(1500, 14)),\n",
       " array([1, 1, 1, ..., 1, 1, 1], shape=(3500,)),\n",
       " array([1, 1, 1, ..., 1, 1, 1], shape=(1500,)))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled, X_test_scaled = scaler.fit_transform(X_train), scaler.transform(X_test)\n",
    "X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.33      0.14         3\n",
      "           1       1.00      0.99      1.00      1497\n",
      "\n",
      "    accuracy                           0.99      1500\n",
      "   macro avg       0.54      0.66      0.57      1500\n",
      "weighted avg       1.00      0.99      0.99      1500\n",
      "\n",
      "[[   1    2]\n",
      " [  10 1487]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "logiregressor = LogisticRegression()\n",
    "logiregressor.fit(X_train_scaled, y_train)\n",
    "y_pred=logiregressor.predict(X_test_scaled)\n",
    "print(f'accuracy: {accuracy_score(y_pred,y_test)}')\n",
    "print(classification_report(y_pred,y_test))\n",
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting High accuracy means dataset might be imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.04      0.07       180\n",
      "           1       0.88      1.00      0.94      1320\n",
      "\n",
      "    accuracy                           0.88      1500\n",
      "   macro avg       0.76      0.52      0.51      1500\n",
      "weighted avg       0.85      0.88      0.83      1500\n",
      "\n",
      "[[   7  173]\n",
      " [   4 1316]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "logiregressor = LogisticRegression(class_weight='balanced')\n",
    "logiregressor.fit(X_train_scaled, y_train)\n",
    "y_pred=logiregressor.predict(X_test_scaled)\n",
    "print(f'accuracy: {accuracy_score(y_pred,y_test)}')\n",
    "print(classification_report(y_pred,y_test))\n",
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will do hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:576: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration 1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "110 fits failed out of a total of 240.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 63, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 63, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 63, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 63, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 63, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 63, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 63, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 63, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1203, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 76, in _check_solver\n",
      "    raise ValueError(\"penalty=None is not supported for the liblinear solver\")\n",
      "ValueError: penalty=None is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan 0.50314286        nan        nan        nan 0.50542857\n",
      " 0.50285714 0.50285714 0.50285714 0.50285714 0.49942857 0.506\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.502             nan 0.502      0.502      0.51457143 0.51085714\n",
      "        nan 0.89942857        nan        nan        nan 0.87457143\n",
      " 0.89914286 0.89657143 0.89885714 0.89914286 0.86571429 0.86057143\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.90085714        nan 0.90057143 0.90085714 0.90142857 0.88771429]\n",
      "  warnings.warn(\n",
      "c:\\Users\\bvkir\\OneDrive\\Desktop\\Machine learning\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;),\n",
       "             param_grid={&#x27;fit_intercept&#x27;: [False, True],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                    &#x27;newton-cholesky&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;),\n",
       "             param_grid={&#x27;fit_intercept&#x27;: [False, True],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                    &#x27;newton-cholesky&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;]})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: LogisticRegression</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, penalty=None, solver=&#x27;sag&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, penalty=None, solver=&#x27;sag&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(class_weight='balanced'),\n",
       "             param_grid={'fit_intercept': [False, True],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
       "                         'solver': ['lbfgs', 'liblinear', 'newton-cg',\n",
       "                                    'newton-cholesky', 'sag', 'saga']})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'penalty':['l1', 'l2', 'elasticnet', None],\n",
    "    'fit_intercept': [False, True],\n",
    "    'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "    }\n",
    "hyperlogiregressor = LogisticRegression(class_weight='balanced')\n",
    "clf = GridSearchCV(hyperlogiregressor, parameters)\n",
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_intercept': True, 'penalty': None, 'solver': 'sag'}\n",
      "0.9014285714285715\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.03      0.06       271\n",
      "           1       0.82      1.00      0.90      1229\n",
      "\n",
      "    accuracy                           0.82      1500\n",
      "   macro avg       0.82      0.52      0.48      1500\n",
      "weighted avg       0.82      0.82      0.75      1500\n",
      "\n",
      "[[   9  262]\n",
      " [   2 1227]]\n"
     ]
    }
   ],
   "source": [
    "y_pred=clf.predict(X_test_scaled)\n",
    "print(f'accuracy: {accuracy_score(y_pred,y_test)}')\n",
    "print(classification_report(y_pred,y_test))\n",
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
